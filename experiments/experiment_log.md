# Experiment Log

## Overview

This log tracks all fine-tuning experiments on Qwen3 models with corrupted math reasoning data.

**Project:** Investigating Internal Reasoning Circuits in Small LLMs  
**Team:** Alex Luu, Vrushank Prakash, Krish Yadav, Gustavo Zepeda  
**Start Date:** [INSERT DATE]

---

## Experiment Template
```markdown
## Experiment [NUMBER]: [MODEL]-[CONFIG]

**Date:** YYYY-MM-DD HH:MM  
**Model:** Qwen/Qwen3-[SIZE]  
**Config:** [CONFIG NAME]  
**GPU:** [T4/A100/etc]

**Hyperparameters:**
- Learning Rate: X.Xe-X
- LoRA Rank: XX
- LoRA Alpha: XX
- Epochs: X
- Batch Size: X Ã— X = X
- Max Length: XXX

**Results:**
- Final Training Loss: X.XX
- Final Validation Loss: X.XX
- Training Time: X.X hours
- Cost: $X.XX

**Observations:**
- [Observation 1]
- [Observation 2]
- [Overfitting observed after epoch X]

**Next Steps:**
- [Action 1]
- [Action 2]
```

---

## Experiments

### Experiment 1: Qwen3-4B-Config1

[Will be filled during execution]

---

### Experiment 2: Qwen3-4B-Config2

[Will be filled during execution]

---

## Summary Table

| Exp | Model | Config | Train Loss | Val Loss | Time (h) | Cost ($) | Notes |
|-----|-------|--------|------------|----------|----------|----------|-------|
| 1   | 4B    | Config1| -          | -        | -        | -        | -     |
| 2   | 4B    | Config2| -          | -        | -        | -        | -     |

---

## Key Findings

[Will be filled after experiments complete]

1. 
2. 
3. 

---

## Questions & Issues

- [ ] Question 1
- [ ] Question 2